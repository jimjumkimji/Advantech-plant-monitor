# backend/dropbox/service.py
import io
from typing import List, Dict, Optional, Literal
from datetime import datetime

import dropbox
import pandas as pd
import numpy as np

from backend.dropbox.env import DROPBOX_TOKEN, WISE4051_ROOT, WISE4012_ROOT

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sensor Columns
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CO2_COL = "COM_1 Wd_0"
TEMP_COL = "COM_1 Wd_1"
HUMID_COL = "COM_1 Wd_2"

# raw bioelectric columns from WISE-4012
LEAF_COL = "AI_0 Val"
GROUND_COL = "AI_1 Val"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CACHE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# RAW cache (per root folder)
_cache: Dict[str, pd.DataFrame] = {}

# REALTIME sensor cache for AI / Backend
_sensor_cache = {
    "wise4051": {"data": None, "last_updated": None},  # CO2 / Temp / Humid
    "wise4012": {"data": None, "last_updated": None},  # Leaf / Ground (+ voltage)
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Dropbox Utils
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_client() -> dropbox.Dropbox:
    return dropbox.Dropbox(DROPBOX_TOKEN)


def list_date_folders(root_path: str) -> List[str]:
    dbx = get_client()
    res = dbx.files_list_folder(root_path)
    folders: List[str] = []

    while True:
        for entry in res.entries:
            if isinstance(entry, dropbox.files.FolderMetadata):
                # à¹ƒà¸Šà¹‰ path_display à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š root_path à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸”
                folders.append(entry.path_display)
        if not res.has_more:
            break
        res = dbx.files_list_folder_continue(res.cursor)

    return folders


def list_csv_files(dbx: dropbox.Dropbox, folder_path: str) -> List[str]:
    res = dbx.files_list_folder(folder_path)
    files: List[str] = []

    while True:
        for entry in res.entries:
            if isinstance(entry, dropbox.files.FileMetadata) and entry.name.lower().endswith(
                ".csv"
            ):
                files.append(entry.path_display)
        if not res.has_more:
            break
        res = dbx.files_list_folder_continue(res.cursor)

    return files


def download_csv_to_df(dbx: dropbox.Dropbox, file_path: str) -> pd.DataFrame:
    _, resp = dbx.files_download(file_path)
    content = resp.content.decode("utf-8", errors="ignore")
    df = pd.read_csv(io.StringIO(content))
    return df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Timestamp Builder
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def add_timestamp_column(df: pd.DataFrame) -> pd.DataFrame:
    if "timestamp" in df.columns:
        return df

    # à¹€à¸„à¸ª WISE-4051: TIM à¹€à¸›à¹‡à¸™ ISO time à¹€à¸Šà¹ˆà¸™ 2025-11-18T14:44:23+07:00
    if "TIM" in df.columns:
        df["timestamp"] = pd.to_datetime(df["TIM"], errors="coerce")
        return df

    cols = {
        "year": ["Year", "YEAR", "year"],
        "month": ["Month", "MONTH", "month"],
        "day": ["Day", "DAY", "day"],
        "hour": ["Hour", "HOUR", "hour"],
        "minute": ["Minute", "MINUTE", "minute"],
        "second": ["Second", "SECOND", "second"],
    }

    def pick(name):
        for c in cols[name]:
            if c in df.columns:
                return c
        return None

    y, m, d = pick("year"), pick("month"), pick("day")
    h, mn, s = pick("hour"), pick("minute"), pick("second")

    if all([y, m, d, h, mn, s]):
        df["timestamp"] = pd.to_datetime(
            dict(
                year=df[y],
                month=df[m],
                day=df[d],
                hour=df[h],
                minute=df[mn],
                second=df[s],
            ),
            errors="coerce",
        )
        return df

    if "Time" in df.columns:
        df["timestamp"] = pd.to_datetime(df["Time"], errors="coerce")
        return df

    raise ValueError("Cannot detect timestamp columns in CSV.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Read All CSV for a Device
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def read_all_csv_under(
    root_path: str,
    use_cache: bool = True,
    skip_old_data: bool = True,
) -> pd.DataFrame:
    # à¹ƒà¸Šà¹‰ cache à¸£à¸°à¸”à¸±à¸š root à¸–à¹‰à¸²à¸¡à¸µ
    if use_cache and root_path in _cache:
        print(f"âœ… Using cached data for {root_path}")
        return _cache[root_path]

    print(f"ğŸ“¥ Reading fresh data from Dropbox: {root_path}")

    dbx = get_client()
    all_rows: List[pd.DataFrame] = []

    folders = list_date_folders(root_path)

    # à¸­à¹ˆà¸²à¸™à¹€à¸‰à¸à¸²à¸°à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¹€à¸à¸·à¹ˆà¸­à¸¥à¸”à¹€à¸§à¸¥à¸²
    if skip_old_data and len(folders) > 7:
        folders = sorted(folders)[-7:]

    for folder in folders:
        csv_files = list_csv_files(dbx, folder)
        for file_path in csv_files:
            try:
                df = download_csv_to_df(dbx, file_path)
                df = add_timestamp_column(df)
                all_rows.append(df)
            except Exception as e:
                print(f"âš ï¸ Failed to read {file_path}: {e}")

    if not all_rows:
        return pd.DataFrame()

    print(f"ğŸ”„ Concatenating {len(all_rows)} dataframes...")
    df_all = pd.concat(all_rows, ignore_index=True)
    df_all = df_all.sort_values("timestamp").reset_index(drop=True)

    if use_cache:
        _cache[root_path] = df_all
        print(f"ğŸ’¾ Cached {len(df_all)} rows")

    return df_all


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Export Cleaner
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def df_to_records(df: pd.DataFrame) -> List[Dict]:
    if df.empty:
        return []
    df = df.replace({np.nan: None})
    return df.to_dict(orient="records")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Aggregation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def aggregate_data(
    df: pd.DataFrame,
    interval: Literal["1min", "5min", "15min", "30min", "1hour"],
) -> pd.DataFrame:
    if df.empty:
        return df

    freq_map = {
        "1min": "1T",
        "5min": "5T",
        "15min": "15T",
        "30min": "30T",
        "1hour": "1H",
    }
    freq = freq_map.get(interval, "5T")

    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    df_numeric = df[["timestamp"] + numeric_cols].copy()

    df_agg = df_numeric.set_index("timestamp").resample(freq).mean().reset_index()
    return df_agg


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Bioelectric Voltage Conversion
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def convert_bioelectric_voltage(df: pd.DataFrame) -> pd.DataFrame:
    """
    à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸² raw ADC à¸‚à¸­à¸‡ LEAF_COL / GROUND_COL à¹€à¸›à¹‡à¸™à¹‚à¸§à¸¥à¸•à¹Œ
    à¹ƒà¸Šà¹‰à¸ªà¸¹à¸•à¸£: V = (Raw - 32768) * 20 / 65535
    """
    if df is None or df.empty:
        return df

    def adc_to_voltage(raw):
        try:
            return (float(raw) - 32768.0) * (20.0 / 65535.0)
        except Exception:
            return None

    if LEAF_COL in df.columns:
        df["Leaf_Voltage"] = df[LEAF_COL].apply(adc_to_voltage)

    if GROUND_COL in df.columns:
        df["Ground_Voltage"] = df[GROUND_COL].apply(adc_to_voltage)

    return df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# High-level RAW accessors
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_co2_all_raw(
    limit: Optional[int] = None,
    interval: Optional[Literal["raw", "1min", "5min", "15min", "30min", "1hour"]] = "raw",
) -> List[Dict]:
    df = read_all_csv_under(WISE4051_ROOT)

    if interval != "raw":
        df = aggregate_data(df, interval)

    if limit:
        df = df.tail(limit)

    return df_to_records(df)


def get_elec_all_raw(
    limit: Optional[int] = None,
    interval: Optional[Literal["raw", "1min", "5min", "15min", "30min", "1hour"]] = "raw",
) -> List[Dict]:
    df = read_all_csv_under(WISE4012_ROOT)

    # à¹à¸›à¸¥à¸‡ bioelectric à¹€à¸›à¹‡à¸™à¹‚à¸§à¸¥à¸•à¹Œà¸à¹ˆà¸­à¸™
    df = convert_bioelectric_voltage(df)

    if interval != "raw":
        df = aggregate_data(df, interval)

    if limit:
        df = df.tail(limit)

    return df_to_records(df)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# REALTIME SENSOR CACHE (for AI + Backend)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def refresh_sensor_cache(
    limit: Optional[int] = 1000,
    interval: Optional[Literal["raw", "1min", "5min", "15min", "30min", "1hour"]] = "5min",
) -> None:
    """
    à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ Dropbox + aggregate + à¹ƒà¸ªà¹ˆà¸¥à¸‡ sensor cache:
      - wise4051: CO2 / Temp / Humid
      - wise4012: Leaf / Ground (+ Leaf_Voltage / Ground_Voltage)
    """
    global _sensor_cache

    print("ğŸ” Refreshing ALL sensors...")

    # ---------- 4051 ----------
    df4051 = read_all_csv_under(WISE4051_ROOT, use_cache=False)

    if not df4051.empty and interval != "raw":
        df4051 = aggregate_data(df4051, interval)

    if not df4051.empty and limit:
        df4051 = df4051.tail(limit)

    if df4051.empty:
        print("âš ï¸ No WISE-4051 data found.")
        _sensor_cache["wise4051"] = {"data": None, "last_updated": None}
    else:
        _sensor_cache["wise4051"] = {
            "data": df4051.copy(),
            "last_updated": datetime.now(),
        }
        print(f"âœ… 4051 cached: {len(df4051)} rows")

    # ---------- 4012 ----------
    df4012 = read_all_csv_under(WISE4012_ROOT, use_cache=False)

    # à¹à¸›à¸¥à¸‡ bioelectric à¹€à¸›à¹‡à¸™à¹‚à¸§à¸¥à¸•à¹Œ
    df4012 = convert_bioelectric_voltage(df4012)

    if not df4012.empty and interval != "raw":
        df4012 = aggregate_data(df4012, interval)

    if not df4012.empty and limit:
        df4012 = df4012.tail(limit)

    if df4012.empty:
        print("âš ï¸ No WISE-4012 data found.")
        _sensor_cache["wise4012"] = {"data": None, "last_updated": None}
    else:
        _sensor_cache["wise4012"] = {
            "data": df4012.copy(),
            "last_updated": datetime.now(),
        }
        print(f"âœ… 4012 cached: {len(df4012)} rows")


def get_sensor_cache():
    return _sensor_cache


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLEAR CACHE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clear_cache():
    global _cache, _sensor_cache
    _cache = {}
    _sensor_cache = {
        "wise4051": {"data": None, "last_updated": None},
        "wise4012": {"data": None, "last_updated": None},
    }
    print("ğŸ§¹ All cache cleared.")